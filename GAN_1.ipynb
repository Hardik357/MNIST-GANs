{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gan_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP5Jt+orlNAQ9uPXGtLh5wm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hardik357/MNIST-GANs/blob/main/GAN_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3BFO4yHhKnO"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X42rgpupjIgR"
      },
      "source": [
        "(train_images, train_labels), (_, _) = keras.datasets.fashion_mnist.load_data()\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images-127.5)/127.5"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLSAvr8RkRx3"
      },
      "source": [
        "BUFFER_SIZE=train_images.shape[0]\n",
        "BATCH_SIZE = 100\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uQfx51blA8L"
      },
      "source": [
        "def make_discriminator_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Conv2D(7, (3,3), padding='same', input_shape=(28,28,1)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dense(50, activation='relu'))\n",
        "    model.add(layers.Dense(1))\n",
        "    return model"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se5tX05ml6fN",
        "outputId": "a0b0c0ea-751f-4be5-e743-46a57e6e2405"
      },
      "source": [
        "model_discriminator = make_discriminator_model()\n",
        "model_discriminator(np.random.rand(1, 28,28,1).astype('float32'))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.05116262]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQf3sMC0mmW8"
      },
      "source": [
        "discriminator_optimizer = tf.optimizers.Adam(1e-3)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3XcuoiimysW"
      },
      "source": [
        "def get_discriminator_loss(real_predictions, fake_predictions):\n",
        "    real_predictions = tf.sigmoid(real_predictions)\n",
        "    fake_predictions = tf.sigmoid(fake_predictions)\n",
        "\n",
        "    real_loss = tf.losses.binary_crossentropy(tf.ones_like(real_predictions), real_predictions)\n",
        "    fake_loss = tf.losses.binary_crossentropy(tf.zeros_like(fake_predictions), fake_predictions)\n",
        "    return fake_loss + real_loss"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO-v8JAzt2TF"
      },
      "source": [
        "def make_generator_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, input_shape=(100, )))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Reshape((7,7,256)))\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (3,3), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (3,3), strides=(2,2), padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Conv2DTranspose(1, (3,3), strides=(2,2), padding='same'))\n",
        "    return model"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeFV2Q7cvwqL"
      },
      "source": [
        "generator = make_generator_model()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6pdv-EPv-KO"
      },
      "source": [
        "def get_generator_loss(fake_predictions):\n",
        "    fake_predictions = tf.sigmoid(fake_predictions)\n",
        "    fake_loss = tf.losses.binary_crossentropy(tf.ones_like(fake_predictions), fake_predictions)\n",
        "    return fake_loss"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_JecNkmw5Xe"
      },
      "source": [
        "generator_optimizer = tf.optimizers.Adam(1e-4)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_6Z7tcEw4kT"
      },
      "source": [
        "def train(dataset, epochs):\n",
        "    for _ in range(epochs):\n",
        "        for images in dataset:\n",
        "            images = tf.cast(images, tf.dtypes.float32)\n",
        "            train_step(images)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajW017T5yksg"
      },
      "source": [
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, 100]).astype('float32')\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise)\n",
        "        real_output = model_discriminator(images)\n",
        "        fake_output = model_discriminator(generated_images)\n",
        "\n",
        "        gen_loss = get_generator_loss(fake_output)\n",
        "        disc_loss = get_discriminator_loss(real_output)\n",
        "\n",
        "        gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "        gradients_of_discriminant = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "        generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "        discriminator_optimizer.apply_gradients(zip(gradients_of_discriminant, model_discriminator.trainable_variables))\n",
        "\n",
        "        print('generator loss: ', np.mean(gen_loss))\n",
        "        print('discriminator loss: ', np.mean(disc_loss))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "kFrtPlM-FE91",
        "outputId": "faa2c058-ecfe-43e2-84f7-8c72bca6e77d"
      },
      "source": [
        "train(train_dataset, 2)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-c69665a1b3e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-51-808cdd7c6c43>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-73821aca1dd7>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgen_tape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mreal_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[0mare\u001b[0m \u001b[0mlooking\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mrelated\u001b[0m \u001b[0mmethods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplease\u001b[0m \u001b[0mrun\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfollowing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         np_config.enable_numpy_behavior()\"\"\".format(type(self).__name__, name))\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: \n        'EagerTensor' object has no attribute 'astype'.\n        If you are looking for numpy-related methods, please run the following:\n        import tensorflow.python.ops.numpy_ops.np_config\n        np_config.enable_numpy_behavior()"
          ]
        }
      ]
    }
  ]
}